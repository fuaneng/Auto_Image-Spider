import requests
import csv
import os
import re
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- é…ç½®å¸¸é‡ (éœ€ä¸åŸçˆ¬è™«è„šæœ¬ä¿æŒä¸€è‡´) ---
ROOT_PATH = r"R:\py\Auto_Image-Spider\Requests\Eporner_R18"
CSV_PATH = os.path.join(ROOT_PATH, "123.csv") 
IMAGE_DIR = os.path.join(ROOT_PATH, "images1")

# ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
os.makedirs(IMAGE_DIR, exist_ok=True)

# æ¨¡æ‹Ÿæµè§ˆå™¨è¯·æ±‚å¤´
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

# --- æ ¸å¿ƒä¸‹è½½å‡½æ•° (ä¸ä¸»è„šæœ¬ä¸­çš„ä¸€è‡´) ---

def download_image(image_info):
    """
    æ ¹æ®å›¾ç‰‡ä¿¡æ¯ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°å¯¹åº”çš„å­æ–‡ä»¶å¤¹ä¸­ã€‚
    """
    url = image_info['å›¾ç‰‡URL']
    title = image_info['æ ‡é¢˜']
    collection_name = image_info['æ‰€å±é›†åˆ'] 
    
    ext_match = re.search(r'\.(\w+)$', url)
    extension = f".{ext_match.group(1)}" if ext_match else ".jpg" 

    safe_title = re.sub(r'[\\/:*?"<>|]', '_', title)
    
    # âš ï¸ å…³é”®ä¿®æ”¹ï¼šæ‰©å±•æ›¿æ¢è§„åˆ™ï¼Œå°† . å’Œ - ä¹Ÿæ›¿æ¢ä¸º _
    safe_collection_name = re.sub(r'[\\/:*?"<>|.-]', '_', collection_name).strip()
    
    sub_dir = os.path.join(IMAGE_DIR, safe_collection_name)
    os.makedirs(sub_dir, exist_ok=True) 

    filename = safe_title + extension
    filepath = os.path.join(sub_dir, filename) 

    if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
        return f"Skipped (Exists in '{safe_collection_name}'): {filename}"
        
    try:
        response = requests.get(url, headers=HEADERS, stream=True, timeout=30)
        response.raise_for_status()

        with open(filepath, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                
        return f"Downloaded to '{safe_collection_name}': {filename}"
        
    except requests.exceptions.RequestException as e:
        return f"Error downloading {filename} to '{safe_collection_name}' from {url}: {e}"
        

def read_data_from_csv(csv_path):
    """
    ä» CSV æ–‡ä»¶ä¸­è¯»å–æ‰€æœ‰å›¾ç‰‡æ•°æ®ã€‚
    å°è¯•å¤šç§ç¼–ç ï¼Œä»¥è§£å†³æ‰‹åŠ¨ç¼–è¾‘å¯¼è‡´çš„ä¸­æ–‡ä¹±ç é—®é¢˜ã€‚
    """
    data_list = []
    # å®šä¹‰å¿…é¡»å­˜åœ¨çš„å­—æ®µ
    required_fields = ['å›¾ç‰‡URL', 'æ ‡é¢˜', 'åç§°', 'æ‰€å±é›†åˆ']
    
    # å°è¯•çš„ç¼–ç åˆ—è¡¨ï¼Œä»æœ€å¯èƒ½æ­£ç¡®çš„å¼€å§‹
    encodings_to_try = ['utf-8-sig', 'utf-8', 'gbk'] 
    
    # å°è¯•è¯»å–æ–‡ä»¶
    for encoding in encodings_to_try:
        try:
            print(f"  [INFO] å°è¯•ä½¿ç”¨ç¼–ç : '{encoding}' è¯»å– CSV æ–‡ä»¶...")
            with open(csv_path, 'r', newline='', encoding=encoding) as csvfile:
                # å¿…é¡»å°†æ–‡ä»¶æŒ‡é’ˆé‡ç½®åˆ°å¼€å¤´ï¼Œä»¥ä¾¿ DictReader é‡æ–°è¯»å–è¡¨å¤´
                csvfile.seek(0)
                reader = csv.DictReader(csvfile)
                
                # æ£€æŸ¥è¡¨å¤´æ˜¯å¦æˆåŠŸåŒ¹é…ï¼ˆå³ç¼–ç æ˜¯å¦æ­£ç¡®ï¼‰
                if not reader.fieldnames or not all(field in reader.fieldnames for field in required_fields):
                    # å¦‚æœè¡¨å¤´ä¸å¯¹ï¼Œè¯´æ˜ç¼–ç ä¸æ­£ç¡®ï¼Œè·³åˆ°ä¸‹ä¸€ä¸ªå°è¯•
                    # print(f"  [DEBUG] ç¼–ç  '{encoding}' å¤±è´¥ï¼Œè¡¨å¤´ä¸åŒ¹é…ã€‚")
                    continue 

                data_list = []
                for row in reader:
                    # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨ä¸”éç©º
                    if all(row.get(f) for f in required_fields):
                        data_list.append(row)
                
                # å¦‚æœæˆåŠŸè¯»å–åˆ°æ•°æ®ï¼ˆä¸”ç¼–ç åŒ¹é…ï¼‰ï¼Œåˆ™è¿”å›
                if data_list:
                    print(f"âœ… æˆåŠŸä½¿ç”¨ç¼–ç  '{encoding}' ä» CSV æ–‡ä»¶ä¸­è¯»å–åˆ° {len(data_list)} æ¡å›¾ç‰‡è®°å½•ã€‚")
                    return data_list

        except FileNotFoundError:
            print(f"ğŸš¨ é”™è¯¯ï¼šæœªæ‰¾åˆ° CSV æ–‡ä»¶: {csv_path}")
            return []
        except UnicodeDecodeError:
            # ç¼–ç é”™è¯¯ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
            continue
        except Exception as e:
            print(f"ğŸš¨ é”™è¯¯ï¼šè¯»å– CSV æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}")
            return []

    print(f"ğŸš¨ é”™è¯¯ï¼šå°è¯•äº†æ‰€æœ‰ç¼–ç  ({', '.join(encodings_to_try)}) å‡æ— æ³•æ­£ç¡®è¯»å– CSV æ–‡ä»¶ã€‚")
    print("è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºç©ºï¼Œæˆ–æ‰‹åŠ¨ç”¨ VS Code/Notepad++ ç­‰è½¯ä»¶å°†å…¶å¦å­˜ä¸º 'UTF-8' æ ¼å¼ã€‚")
    return []


def start_download_executor(all_data):
    """ä½¿ç”¨ThreadPoolExecutorå¯åŠ¨å¤šçº¿ç¨‹ä¸‹è½½"""
    if not all_data:
        print("æ²¡æœ‰å›¾ç‰‡æ•°æ®å¯ä¾›ä¸‹è½½ã€‚")
        return
        
    MAX_WORKERS = 10 
    success_count = 0
    error_count = 0
    total_tasks = len(all_data)
    
    print(f"\nâš¡ å¯åŠ¨ {total_tasks} ä¸ªå¤šçº¿ç¨‹ä¸‹è½½ä»»åŠ¡...")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_info = {executor.submit(download_image, item): item for item in all_data}
        
        for i, future in enumerate(as_completed(future_to_info)):
            try:
                result = future.result()
                if result.startswith("Downloaded"):
                    success_count += 1
                elif result.startswith("Error"):
                    error_count += 1
                
                print(f"  [è¿›åº¦ {i+1}/{total_tasks}] {result}")

            except Exception as exc:
                print(f"  [EXCEPTION] ä»»åŠ¡æ‰§è¡Œæ—¶å‘ç”Ÿå¼‚å¸¸: {exc}")
                error_count += 1
                
    print(f"\nğŸ‰ æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å®Œæˆï¼ æˆåŠŸ: {success_count}ï¼Œ å¤±è´¥/è·³è¿‡: {total_tasks - success_count}ï¼Œ é”™è¯¯: {error_count}")

# --- ä¸»é€»è¾‘ ---
def main():
    # 1. ä» CSV æ–‡ä»¶è¯»å–æ•°æ®
    all_data = read_data_from_csv(CSV_PATH)
    
    if not all_data:
        print("æ— æ³•ç»§ç»­ä¸‹è½½ï¼Œè¯·ç¡®ä¿ CSV æ–‡ä»¶å­˜åœ¨ä¸”åŒ…å«æ•°æ®ã€‚")
        return
        
    # 2. å¯åŠ¨ä¸‹è½½æ‰§è¡Œå™¨
    start_download_executor(all_data)

if __name__ == '__main__':
    main()