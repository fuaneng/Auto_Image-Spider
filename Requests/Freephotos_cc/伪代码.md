帮我设计高效的爬虫代码，下面的伪代码中已经给出相关信息和必要的条件：


请求网址："https://freephotos.cc/search/{tag}",请求方法：GET
示例网址："https://freephotos.cc/search/dog"
Doc文档response响应示例：
```html

                        <div class="columns-1 md:columns-2 lg:columns-3 gap-4 space-y-4">
                            <div class="h-min w-full hover:scale-102 hover:opacity-90 hover:drop-shadow-sm transition duration-150">
                                <a class="block" style="background-image:url(https://imagedelivery.net/WS9ABFRS6TfdqDudkFOT3w/grrraphic/previews/PtUkmGvPt7ylOJrJq2NGH20PfLaCCZXhzsOZ5XgF.jpeg/blurthumb);background-size:cover;background-position:center" href="/photo/a-hot-dog-with-chips-and-condiments-on-a-plate-1a">
                                    <img src="https://imagedelivery.net/WS9ABFRS6TfdqDudkFOT3w/grrraphic/previews/PtUkmGvPt7ylOJrJq2NGH20PfLaCCZXhzsOZ5XgF.jpeg/thumb" loading="lazy" class="w-full object-cover rounded" alt="a hot dog with chips and condiments on a plate"/>
                                </a>
                            </div>

```
提取字段：
- 提取预览图片名称并拼接最终的直链下载地址：提取'a'元素下的'href'值，即'href="/photo/a-hot-dog-with-chips-and-condiments-on-a-plate-1a"，去除"/photo/",加上前缀“https://freephotos.cc/api/download/”即为原图下载直链，示例："https://freephotos.cc/api/download/a-hot-dog-with-chips-and-condiments-on-a-plate-1a"就是原图下载直链。


- 'img'的'alt'值,如：'img'属性下的'alt'值`alt="a hot dog with chips and condiments on a plate"`就是图片标题

- 图片名称 (ImageName) —— 同样使用'href'的值(去除"/photo/"之后的值），示例"a-hot-dog-with-chips-and-condiments-on-a-plate-1a"


{tag}文本本地文件路径：D:\myproject\Code\爬虫\爬虫数据\libreshot\ram_tag_list_备份.txt

将获取后的所有数据分列实时保存到CSV文件
    def write_to_csv(self, title, name, url, csv_path, tag):
        """
        写入 CSV 方法，已集成线程锁，确保多线程安全。
        """
        try:
            with self.csv_lock: # 使用线程锁
                os.makedirs(os.path.dirname(csv_path), exist_ok=True)
                is_file_empty = not os.path.exists(csv_path) or os.stat(csv_path).st_size == 0
                
                with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    
                    if is_file_empty:
                        writer.writerow(['Title', 'ImageName', 'URL', 'TAG'])
                        
                    writer.writerow([title, name, url, tag])
        except Exception as e:
            print(f"[{tag}] [✗] 写入 CSV 出错: {e}")


多线程完全解耦式爬取{tag}以及异步下载图片，线程数可配置为，10个标签处理线程，20个线程下载
异步爬取和下载增加断点记录功能，方便下次运行爬虫可以接续

Redis 去重逻辑示例
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_KEY = 'libreshot_image_url_set' # 使用 URL 作为唯一标识符



    def __init__(self, csv_dir_path, csv_filename, redis_host=REDIS_HOST, redis_port=REDIS_PORT):
        """
        初始化爬虫实例，集成 Redis/内存去重逻辑。
        """
        self.csv_dir_path = csv_dir_path
        self.csv_path = os.path.join(self.csv_dir_path, csv_filename) 
        self.csv_lock = Lock() # 用于 CSV 写入的线程锁
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        # --- 去重初始化逻辑 ---
        try:
            # 尝试连接 Redis
            self.redis = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)
            # 尝试执行一次 ping 来验证连接
            self.redis.ping()
            print("✅ Redis 连接成功，使用 Redis 集合进行去重。")
        except redis.exceptions.ConnectionError as e:
            print(f"⚠️ Redis 连接失败 ({e})，将使用内存去重。")
            self.redis = None
            # 内存去重集合，注意：内存集合在多线程间共享，但只在当前程序生命周期内有效。
            # 由于线程池是在当前进程内运行，因此这个 set 是共享的。
            self.visited_urls = set()
        except Exception as e:
            print(f"⚠️ Redis 初始化遇到其他错误 ({e})，将使用内存去重。")
            self.redis = None
            self.visited_urls = set()