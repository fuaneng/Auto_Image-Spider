import os
import csv
import re
import time
import requests
import urllib3
import redis
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

# ----------------- é…ç½®å¸¸é‡ -----------------
# ç½‘ç«™åŸºç¡€ä¿¡æ¯
BASE_URL = "https://freephotos.cc"
SEARCH_URL_TEMPLATE = f"{BASE_URL}/search/{{tag}}"
DOWNLOAD_URL_PREFIX = f"{BASE_URL}/api/download/"

# æ–‡ä»¶è·¯å¾„å’Œåç§°
TAG_FILE_PATH = r'D:\myproject\Code\çˆ¬è™«\çˆ¬è™«æ•°æ®\libreshot\ram_tag_list_å¤‡ä»½.txt'
CSV_DIR = r'D:\myproject\Code\çˆ¬è™«\çˆ¬è™«æ•°æ®\libreshot\csv_output'
CSV_FILENAME = 'image_data.csv'
CHECKPOINT_FILE = 'completed_tags.txt'

# Redis é…ç½®
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_KEY = 'freephotos_image_url_set' # ä½¿ç”¨ ImageName (URL Path) ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦

# çº¿ç¨‹é…ç½®
TAG_PROCESS_THREADS = 10 # æ ‡ç­¾å¤„ç†çº¿ç¨‹æ•°
# DOWNLOAD_THREADS = 20    # å›¾ç‰‡ä¸‹è½½çº¿ç¨‹æ•°ï¼ˆæˆ‘ä»¬å°†ä½¿ç”¨çº¿ç¨‹æ± å®ç°ï¼‰

class ImageScraper:
    """
    é«˜æ•ˆã€å¤šçº¿ç¨‹å›¾ç‰‡ä¿¡æ¯çˆ¬è™«ç±»ã€‚
    è´Ÿè´£æ ‡ç­¾å¤„ç†ã€ç½‘é¡µè¯·æ±‚ã€æ•°æ®è§£æã€å»é‡å’Œ CSV å†™å…¥ã€‚
    """
    def __init__(self, csv_dir_path, csv_filename, redis_host=REDIS_HOST, redis_port=REDIS_PORT):
        """
        åˆå§‹åŒ–çˆ¬è™«å®ä¾‹ï¼Œé›†æˆ Redis/å†…å­˜å»é‡é€»è¾‘ã€‚
        """
        self.csv_dir_path = csv_dir_path
        self.csv_path = os.path.join(self.csv_dir_path, csv_filename) 
        self.csv_lock = Lock() # ç”¨äº CSV å†™å…¥çš„çº¿ç¨‹é”
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        # å¿½ç•¥ SSL è­¦å‘Š
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        # å·²å®Œæˆæ ‡ç­¾é›†åˆï¼ˆç”¨äºæ–­ç‚¹ç»­çˆ¬ï¼‰
        self.completed_tags = self._load_completed_tags()
        self.tag_lock = Lock() # ç”¨äºæ›´æ–° completed_tags å’Œæ–­ç‚¹æ–‡ä»¶çš„çº¿ç¨‹é”

        # --- å»é‡åˆå§‹åŒ–é€»è¾‘ ---
        self.redis = None
        self.visited_names = set() # å†…å­˜å»é‡é›†åˆ
        try:
            # å°è¯•è¿æ¥ Redis
            self.redis = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)
            self.redis.ping()
            print("âœ… Redis è¿æ¥æˆåŠŸï¼Œä½¿ç”¨ Redis é›†åˆè¿›è¡Œå»é‡ã€‚")
        except redis.exceptions.ConnectionError as e:
            print(f"âš ï¸ Redis è¿æ¥å¤±è´¥ ({e})ï¼Œå°†ä½¿ç”¨å†…å­˜å»é‡ã€‚")
        except Exception as e:
            print(f"âš ï¸ Redis åˆå§‹åŒ–é‡åˆ°å…¶ä»–é”™è¯¯ ({e})ï¼Œå°†ä½¿ç”¨å†…å­˜å»é‡ã€‚")
        
    def _load_completed_tags(self):
        """åŠ è½½å·²å®Œæˆçš„æ ‡ç­¾ï¼Œç”¨äºæ–­ç‚¹ç»­çˆ¬ã€‚"""
        if os.path.exists(CHECKPOINT_FILE):
            with open(CHECKPOINT_FILE, 'r', encoding='utf-8') as f:
                return set(line.strip() for line in f if line.strip())
        return set()

    def _mark_tag_completed(self, tag):
        """å°†æ ‡ç­¾æ ‡è®°ä¸ºå·²å®Œæˆï¼Œå¹¶ä¿å­˜åˆ°æ–­ç‚¹æ–‡ä»¶ã€‚"""
        with self.tag_lock:
            if tag not in self.completed_tags:
                self.completed_tags.add(tag)
                with open(CHECKPOINT_FILE, 'a', encoding='utf-8') as f:
                    f.write(f"{tag}\n")

    def is_name_visited(self, image_name):
        """
        æ£€æŸ¥å›¾ç‰‡åç§°ï¼ˆImageNameï¼Œå³ä¸‹è½½è·¯å¾„ä¸­çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼‰æ˜¯å¦å·²è¢«è®¿é—®ã€‚
        ä½¿ç”¨ Redis æˆ–å†…å­˜é›†åˆè¿›è¡Œå»é‡ã€‚
        """
        if self.redis:
            # ä½¿ç”¨ Redis çš„ sadd æ–¹æ³•ï¼Œå¦‚æœå…ƒç´ å·²å­˜åœ¨ï¼Œè¿”å› 0ï¼›å¦åˆ™ï¼Œè¿”å› 1
            # æˆ‘ä»¬å°† ImageName ä½œä¸ºå”¯ä¸€æ ‡è¯†
            is_new = self.redis.sadd(REDIS_KEY, image_name)
            return is_new == 0
        else:
            # å†…å­˜å»é‡
            with self.tag_lock: # ä½¿ç”¨é”ç¡®ä¿å†…å­˜é›†åˆçš„å¤šçº¿ç¨‹å®‰å…¨
                if image_name in self.visited_names:
                    return True
                self.visited_names.add(image_name)
                return False

    def write_to_csv(self, title, name, url, tag):
        """
        å†™å…¥ CSV æ–¹æ³•ï¼Œå·²é›†æˆçº¿ç¨‹é”ï¼Œç¡®ä¿å¤šçº¿ç¨‹å®‰å…¨ã€‚
        """
        # ä½¿ç”¨ self.csv_path å’Œ self.csv_lock æ›¿æ¢ä¼ªä»£ç ä¸­çš„å‚æ•°
        try:
            with self.csv_lock: # ä½¿ç”¨çº¿ç¨‹é”
                os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨æˆ–æ˜¯å¦ä¸ºç©º
                is_file_empty = not os.path.exists(self.csv_path) or os.stat(self.csv_path).st_size == 0
                
                with open(self.csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    
                    if is_file_empty:
                        writer.writerow(['Title', 'ImageName', 'URL', 'TAG'])
                        
                    writer.writerow([title, name, url, tag])
        except Exception as e:
            print(f"[{tag}] [âœ—] å†™å…¥ CSV å‡ºé”™: {e}")

    def _parse_and_save(self, html_content, tag):
        """
        è§£æ HTML å†…å®¹ï¼Œæå–æ‰€éœ€æ•°æ®ï¼Œå¹¶è¿›è¡Œå»é‡å’Œä¿å­˜ã€‚
        """
        if not html_content:
            return

        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æŸ¥æ‰¾åŒ…å«å›¾ç‰‡çš„çˆ¶ div
        image_containers = soup.select('div.columns-1 div.h-min.w-full a')

        count = 0
        for a_tag in image_containers:
            try:
                # 1. æå– 'a' å…ƒç´ çš„ 'href'
                href = a_tag.get('href') # ç¤ºä¾‹: /photo/a-hot-dog-with-chips-and-condiments-on-a-plate-1a

                if not href or not href.startswith('/photo/'):
                    continue

                # 2. æå–å›¾ç‰‡åç§° (ImageName)
                image_name = href.replace('/photo/', '').strip() # ç¤ºä¾‹: a-hot-dog-with-chips-and-condiments-on-a-plate-1a
                
                # 3. è¿›è¡Œå»é‡æ£€æŸ¥
                if self.is_name_visited(image_name):
                    print(f"[{tag}] [SKIP] å·²çˆ¬å–: {image_name}")
                    continue

                # 4. æ‹¼æ¥æœ€ç»ˆçš„ç›´é“¾ä¸‹è½½åœ°å€ (URL)
                download_url = DOWNLOAD_URL_PREFIX + image_name

                # 5. æå–å›¾ç‰‡æ ‡é¢˜ (Title)
                img_tag = a_tag.find('img')
                title = img_tag.get('alt') if img_tag and img_tag.get('alt') else "N/A"

                # 6. å†™å…¥ CSV
                self.write_to_csv(title, image_name, download_url, tag)
                count += 1
                
            except Exception as e:
                print(f"[{tag}] [âœ—] è§£ææˆ–ä¿å­˜å•ä¸ªå›¾ç‰‡æ•°æ®å‡ºé”™: {e}")

        print(f"[{tag}] [âœ“] å®Œæˆè§£æå’Œä¿å­˜ï¼Œæ–°å¢ {count} æ¡è®°å½•ã€‚")

    def fetch_tag_page(self, tag):
        """
        å¤šçº¿ç¨‹å·¥ä½œå‡½æ•°ï¼šè¯·æ±‚å•ä¸ªæ ‡ç­¾çš„é¡µé¢å¹¶å¤„ç†æ•°æ®ã€‚
        """
        if tag in self.completed_tags:
            print(f"[{tag}] [SKIP] æ ‡ç­¾å·²åœ¨æ–­ç‚¹è®°å½•ä¸­ï¼Œè·³è¿‡ã€‚")
            return

        url = SEARCH_URL_TEMPLATE.format(tag=tag)
        print(f"[{tag}] [i] æ­£åœ¨è¯·æ±‚ URL: {url}")
        
        try:
            # ç½‘ç«™å¯èƒ½æœ‰å¤šé¡µï¼Œä½†ä¼ªä»£ç åªç»™å‡ºäº†å•é¡µä¿¡æ¯ï¼Œæˆ‘ä»¬æš‚æ—¶åªçˆ¬å–ç¬¬ä¸€é¡µ
            response = requests.get(url, headers=self.headers, verify=False, timeout=60)    # 60 ç§’è¶…æ—¶
            response.raise_for_status() # æ£€æŸ¥ HTTP çŠ¶æ€ç 
            
            self._parse_and_save(response.text, tag)
            self._mark_tag_completed(tag) # æ ‡è®°æ ‡ç­¾å¤„ç†å®Œæˆ

        except requests.exceptions.RequestException as e:
            print(f"[{tag}] [âœ—] è¯·æ±‚å¤±è´¥: {e}")
        except Exception as e:
            print(f"[{tag}] [âœ—] å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

    def load_tags(self):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å¾…å¤„ç†çš„æ ‡ç­¾åˆ—è¡¨ã€‚"""
        try:
            with open(TAG_FILE_PATH, 'r', encoding='utf-8') as f:
                # å»é™¤ç©ºè¡Œå’Œé¦–å°¾ç©ºæ ¼
                tags = [line.strip() for line in f if line.strip()]
                print(f"âœ… æˆåŠŸåŠ è½½ {len(tags)} ä¸ªæ ‡ç­¾ã€‚")
                return tags
        except FileNotFoundError:
            print(f"âŒ æ ‡ç­¾æ–‡ä»¶æœªæ‰¾åˆ°: {TAG_FILE_PATH}")
            return []
        except Exception as e:
            print(f"âŒ åŠ è½½æ ‡ç­¾æ–‡ä»¶å‡ºé”™: {e}")
            return []

    def run_scraper(self):
        """
        å¯åŠ¨å¤šçº¿ç¨‹çˆ¬è™«ä¸»æµç¨‹ã€‚
        """
        tags = self.load_tags()
        if not tags:
            return

        # ä½¿ç”¨ ThreadPoolExecutor å®ç°å¤šçº¿ç¨‹çˆ¬å–æ ‡ç­¾
        print(f"\nğŸš€ å¯åŠ¨æ ‡ç­¾å¤„ç†ï¼Œçº¿ç¨‹æ•°: {TAG_PROCESS_THREADS}")
        start_time = time.time()
        
        # ç­›é€‰å‡ºæœªå®Œæˆçš„æ ‡ç­¾
        tags_to_process = [tag for tag in tags if tag not in self.completed_tags]
        print(f"âœ¨ å¾…å¤„ç†æ ‡ç­¾: {len(tags_to_process)} ä¸ª (å·²è·³è¿‡ {len(tags) - len(tags_to_process)} ä¸ªå·²å®Œæˆæ ‡ç­¾)ã€‚")

        with ThreadPoolExecutor(max_workers=TAG_PROCESS_THREADS) as executor:
            # æäº¤ä»»åŠ¡
            future_to_tag = {executor.submit(self.fetch_tag_page, tag): tag for tag in tags_to_process}
            
            # å®æ—¶è·å–ä»»åŠ¡ç»“æœ
            for future in as_completed(future_to_tag):
                tag = future_to_tag[future]
                try:
                    # ç»“æœå·²è¢« fetch_tag_page å‡½æ•°å†…éƒ¨å¤„ç†
                    future.result() 
                except Exception as exc:
                    print(f'[{tag}] [âœ—] ç”Ÿæˆäº†ä¸€ä¸ªå¼‚å¸¸: {exc}')

        end_time = time.time()
        print(f"\nğŸ‰ æ‰€æœ‰æ ‡ç­¾å¤„ç†å®Œæ¯•! æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’ã€‚")
        
        # --- å¼‚æ­¥/å¤šçº¿ç¨‹ä¸‹è½½éƒ¨åˆ†ï¼ˆå¯æ‰©å±•ï¼‰---
        # è¿™é‡Œå¯ä»¥åŠ å…¥å¯åŠ¨å¼‚æ­¥ä¸‹è½½å™¨çš„é€»è¾‘ï¼Œä¾‹å¦‚ï¼š
        # self.start_download_manager()

# ----------------- ç¤ºä¾‹è¿è¡Œ -----------------
if __name__ == '__main__':
    
    # ç¡®ä¿ CSV ç›®å½•å­˜åœ¨
    os.makedirs(CSV_DIR, exist_ok=True)
    
    # å®ä¾‹åŒ–çˆ¬è™«å¹¶è¿è¡Œ
    scraper = ImageScraper(
        csv_dir_path=CSV_DIR, 
        csv_filename=CSV_FILENAME
    )
    
    scraper.run_scraper()