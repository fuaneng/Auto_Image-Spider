from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException
import os, time, hashlib, redis, csv, threading, random, re, urllib.parse


class VintageStockPhotos:
    def __init__(self, chrome_driver_path):
        service = Service(executable_path=chrome_driver_path)
        options = Options()
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        # options.add_argument('--headless')    # æ— å¤´æ¨¡å¼
        # options.add_argument('--window-size=1920,1080')  # è®¾ç½®çª—å£å¤§å°
        options.add_argument('--disable-gpu')   # ç¦ç”¨GPUåŠ é€Ÿ
        self.driver = webdriver.Chrome(service=service, options=options)

        self.base_url = 'https://vintagestockphotos.com/'
        self.csv_lock = threading.Lock()
        self.redis_key = 'image_md5_set_vintagestockphotos'

        try:
            self.redis = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
            self.redis.ping()
            print("âœ… Redis è¿æ¥æˆåŠŸã€‚")
        except Exception:
            print("âš ï¸ Redis ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨å†…å­˜å»é‡ã€‚")
            self.redis = None
            self.visited_md5 = set()

    # ---------------------- æå–å½“å‰é¡µå›¾ç‰‡ ----------------------
    def get_images(self, tag, csv_path):
        print(f"--- æ­£åœ¨è§£æã€{tag}ã€‘çš„å›¾ç‰‡åˆ—è¡¨...")

        wait = WebDriverWait(self.driver, 20)
        try:
            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.tabs_content div.flex-images22')))
            print("[âˆš] ä¸»å›¾ç‰‡å®¹å™¨åŠ è½½å®Œæˆã€‚")
        except TimeoutException:
            print("[âœ—] é¡µé¢åŠ è½½è¶…æ—¶ã€‚")
            return

        # æ»šåŠ¨åŠ è½½æ‰€æœ‰å›¾ç‰‡
        last_count = 0
        while True:
            image_elements = self.driver.find_elements(By.CSS_SELECTOR, 'div.flex-images22 div.item')
            if len(image_elements) == last_count and last_count > 0:
                break
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            last_count = len(image_elements)
            time.sleep(random.uniform(1.5, 2.5))

        print(f"ğŸ“¸ å…±æ£€æµ‹åˆ° {len(image_elements)} å¼ å›¾ç‰‡ã€‚")
        
        # éå†å›¾ç‰‡å…ƒç´ ï¼Œæå–ä¿¡æ¯
        for card_ele in image_elements:
            try:
                img_ele = card_ele.find_element(By.CSS_SELECTOR, 'a.image img')
                image_url = img_ele.get_attribute('src') or ""
                mouse_attr = img_ele.get_attribute('onmouseover') or ""

                # --- ä» onmouseover ä¸­æå–æ ‡é¢˜ ---
                match = re.search(r"trailOn\('[^']*','([^']*)'", mouse_attr)
                title = match.group(1).strip() if match else "Untitled"

                # --- æ„é€ åŸå›¾ URL ---
                image_url_cleaned = image_url.replace("thumbnail", "sample")    # æ›¿æ¢ä¸ºæ›´é«˜åˆ†è¾¨ç‡çš„å›¾ç‰‡

                # --- å»é‡ ---
                md5_hash = hashlib.md5(image_url_cleaned.encode('utf-8')).hexdigest()
                if self.is_duplicate(md5_hash):
                    continue

                # --- å†™å…¥ CSV ---
                image_name = os.path.basename(image_url_cleaned)
                self.write_to_csv(title, image_name, image_url_cleaned, csv_path, tag)
                print(f"âœ”ï¸ æå–æˆåŠŸï¼š{title}")

            except Exception as e:
                print(f"[âœ—] æå–å›¾ç‰‡ä¿¡æ¯å¤±è´¥: {e}")

    # ---------------------- å»é‡é€»è¾‘ ----------------------
    def is_duplicate(self, md5_hash):
        if self.redis:
            if self.redis.sismember(self.redis_key, md5_hash):
                return True
            self.redis.sadd(self.redis_key, md5_hash)
        else:
            if md5_hash in self.visited_md5:
                return True
            self.visited_md5.add(md5_hash)
        return False

    # ---------------------- å†™å…¥ CSV ----------------------
    def write_to_csv(self, title, name, url, csv_path, tag):
        try:
            with self.csv_lock:
                with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    if f.tell() == 0:
                        writer.writerow(['Title', 'ImageName', 'URL', 'Tag'])
                    writer.writerow([title, name, url, tag])
            print(f"ğŸ’¾ å†™å…¥æˆåŠŸ: {name}")
        except Exception as e:
            print(f"[âœ—] å†™å…¥ CSV å‡ºé”™: {e}")

    # ---------------------- ç¿»é¡µé€»è¾‘ ----------------------
    def crawl_page(self, tag, csv_path):
        page_num = 1
        wait = WebDriverWait(self.driver, 15)

        while True:
            print(f"\n=== æ­£åœ¨çˆ¬å–ã€{tag}ã€‘ç¬¬ {page_num} é¡µ ===")
            self.get_images(tag, csv_path)

            try:
                next_btn = self.driver.find_element(By.LINK_TEXT, "Next Â»")
                self.driver.execute_script("arguments[0].click();", next_btn)
                time.sleep(random.uniform(2.5, 4))
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'div.flex-images22 div.item'))) # ç­‰å¾…æ–°å†…å®¹åŠ è½½
                page_num += 1
            except Exception:
                print(f"[å®Œæˆ] ã€{tag}ã€‘å…±çˆ¬å– {page_num} é¡µã€‚")
                break

    # ---------------------- ä¸»å‡½æ•° ----------------------
    def main(self):
        save_dir = r'D:\work\çˆ¬è™«\çˆ¬è™«æ•°æ®\vintagestockphotos'  # è¯·ä¿®æ”¹ä¸ºä½ çš„ä¿å­˜ç›®å½•
        tag_file_path = os.path.join(save_dir, r'D:\work\çˆ¬è™«\çˆ¬è™«æ•°æ®\vintagestockphotos\ram_tag_list_å¤‡ä»½.txt')   # è¯·ä¿®æ”¹ä¸ºä½ çš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„
        os.makedirs(save_dir, exist_ok=True)
        csv_path = os.path.join(save_dir, 'all_records_01.csv')

        try:
            with open(tag_file_path, 'r', encoding='utf-8') as f:
                tags = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            print(f"[é”™è¯¯] æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶: {tag_file_path}")
            return

        print(f"--- å‘ç° {len(tags)} ä¸ªæ ‡ç­¾ ---")

        for tag in tags:
            try:
                encoded_tag = urllib.parse.quote_plus(tag)
                search_url = f"{self.base_url}search.php?search={encoded_tag}&gid_search=&match=all"
                print(f"\n--- å¼€å§‹å¤„ç†ï¼šã€{tag}ã€‘ ---\nURL: {search_url}")
                self.driver.get(search_url)
                time.sleep(random.uniform(3, 5))

                # âœ… æ–°å¢ï¼šæ£€æµ‹æ˜¯å¦å­˜åœ¨ç»“æœ
                try:
                    WebDriverWait(self.driver, 10).until(
                        lambda d: d.find_elements(By.CSS_SELECTOR, "div.flex-images22")
                    )
                    image_items = self.driver.find_elements(By.CSS_SELECTOR, "div.flex-images22 div.item")
                    if not image_items:
                        print(f"[è·³è¿‡] {tag} æ— æœç´¢ç»“æœï¼ˆæ— å›¾ç‰‡å…ƒç´ ï¼‰ã€‚")
                        continue
                except TimeoutException:
                    print(f"[è·³è¿‡] {tag} é¡µé¢æœªåŠ è½½å‡ºå›¾ç‰‡å®¹å™¨ã€‚")
                    continue

                self.crawl_page(tag, csv_path)
            except Exception as e:
                print(f"[âœ—] å¤„ç†æ ‡ç­¾ {tag} å‡ºé”™: {e}")

        self.driver.quit()


if __name__ == '__main__':
    chrome_driver_path = r'C:\Program Files\Google\chromedriver-win64\chromedriver.exe' # è¯·ä¿®æ”¹ä¸ºä½ çš„chromedriverè·¯å¾„
    spider = VintageStockPhotos(chrome_driver_path)
    try:
        spider.main()
    finally:
        spider.driver.quit()
