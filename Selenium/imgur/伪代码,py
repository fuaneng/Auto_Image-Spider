
下面是我的伪爬虫代码设计和逻辑，请使用selenium实例爬取：请完善爬虫代码。
主页：https://imgur.com/
搜索标签：https://imgur.com/t/{tag}
请求网址："https://api.imgur.com/post/v1/posts/t/{tag}?client_id=d70305e7c3ac5c6&filter%5Bwindow%5D=week&include=adtiles%2Cadconfig%2Ccover&location=desktoptag&page={页数}&sort=-viral",请求方法：GET  
翻页："https://www.piqsels.com/en/search?q={tag}&page={页数}" 如果返回404，说明没有下页了

示例网址："https://api.imgur.com/post/v1/posts/t/girl?client_id=d70305e7c3ac5c6&filter%5Bwindow%5D=week&include=adtiles%2Cadconfig%2Ccover&location=desktoptag&page=1&sort=-viral"


network下的日志和缓存
fetch/XHR文档response响应示例：


    "posts": [
        {
                    "id": "u3ATgpC",
                    "account_id": 85190273,
                    "title": "Robyn the Guard (Miltonius' Akumi fanart) [by me]",
                    "seo_title": "robyn-guard-miltonius-akumi-fanart-by-me",
                    "description": "",
                    "view_count": 274,
                    "upvote_count": 9,
                    "downvote_count": 2,
                    "point_count": 7,
                    "image_count": 2,
                    "comment_count": 0,
                    "favorite_count": 2,
                    "virality": 30626.845098040016,
                    "score": 7.099,
                    "in_most_viral": false,
                    "is_album": true,
                    "is_mature": false,
                    "cover_id": "C1WRtaf",
                    "created_at": "2025-09-20T20:17:04Z",
                    "updated_at": null,
                    "url": "https://imgur.com/gallery/robyn-guard-miltonius-akumi-fanart-by-me-u3ATgpC",
                    "privacy": "private",
                    "vote": null,
                    "favorite": false,
                    "is_ad": false,
                    "ad_type": 0,
                    "ad_url": "",
                    "include_album_ads": false,
                    "shared_with_community": true,
                    "is_pending": false,
                    "platform": "android",
                    "ad_config": {
                        "show_ads": true,
                        "show_ad_level": 2,
                        "ad_sense_client_id": "",
                        "nsfw_score": 0,
                        "safe_flags": [
                            "album",
                            "in_gallery"
                        ],
                        "high_risk_flags": [],
                        "unsafe_flags": [],
                        "wall_unsafe_flags": []
                    },
                    "cover": {
                        "id": "C1WRtaf",
                        "account_id": 85190273,
                        "mime_type": "image/jpeg",
                        "type": "image",
                        "name": "",
                        "basename": "",
                        "url": "https://i.imgur.com/C1WRtaf.jpeg",
                        "ext": "jpeg",
                        "width": 2998,
                        "height": 2998,
                        "size": 1498489,
                        "metadata": {
                            "title": "",
                            "description": "",
                            "is_animated": false,
                            "is_looping": false,
                            "duration": 0,
                            "has_sound": false
                        },
                        "created_at": "2025-09-20T20:16:57Z",
                        "updated_at": null
                    },
                    "display": []
                },

根据"mime_type"值判定是否图片,'image/图片格式'：示例："mime_type": "image/jpeg",如果是"mime_type": "video/mp4",则不是图片，不需要提取相关信息。
如果是则进行提取相关信息:
在"cover"下的值提取url，示例: "url": "https://i.imgur.com/C1WRtaf.jpeg"
提取标题：'title'的值就是标题：示例："title": "Robyn the Guard (Miltonius' Akumi fanart) [by me]",
图片名称使用url中的字段


{tag}文本本地文件路径：D:\myproject\Code\爬虫\爬虫数据\libreshot\ram_tag_list_备份.txt
CSV文件存储路径:r"D:\myproject\Code\爬虫\爬虫数据\imgur"

将获取后的所有数据分列实时保存到CSV文件
    def write_to_csv(self, title, name, url, csv_path, tag):
        """
        写入 CSV 方法，已集成线程锁，确保线程安全。
        """
        try:
            with self.csv_lock: # 使用线程锁
                os.makedirs(os.path.dirname(csv_path), exist_ok=True)
                is_file_empty = not os.path.exists(csv_path) or os.stat(csv_path).st_size == 0
                
                with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    
                    if is_file_empty:
                        writer.writerow(['Title', 'ImageName', 'URL', 'TAG'])
                        
                    writer.writerow([title, name, url, tag])
        except Exception as e:
            print(f"[{tag}] [✗] 写入 CSV 出错: {e}")


异步多线程爬取{tag}，设置20线程爬取

Redis 去重逻辑示例
REDIS_HOST = 'localhost'
REDIS_PORT = 6379
REDIS_KEY = 'imgur_image_url_set' # 使用 URL 作为唯一标识符



    def __init__(self, csv_dir_path, csv_filename, redis_host=REDIS_HOST, redis_port=REDIS_PORT):
        """
        初始化爬虫实例，集成 Redis/内存去重逻辑。
        """
        self.csv_dir_path = csv_dir_path
        self.csv_path = os.path.join(self.csv_dir_path, csv_filename) 
        self.csv_lock = Lock() # 用于 CSV 写入的线程锁
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

        # --- 去重初始化逻辑 ---
        try:
            # 尝试连接 Redis
            self.redis = redis.StrictRedis(host=redis_host, port=redis_port, decode_responses=True)
            # 尝试执行一次 ping 来验证连接
            self.redis.ping()
            print("✅ Redis 连接成功，使用 Redis 集合进行去重。")
        except redis.exceptions.ConnectionError as e:
            print(f"⚠️ Redis 连接失败 ({e})，将使用内存去重。")
            self.redis = None
            # 内存去重集合，注意：内存集合在多线程间共享，但只在当前程序生命周期内有效。
            # 由于线程池是在当前进程内运行，因此这个 set 是共享的。
            self.visited_urls = set()
        except Exception as e:
            print(f"⚠️ Redis 初始化遇到其他错误 ({e})，将使用内存去重。")
            self.redis = None
            self.visited_urls = set()

chrome_driver_path = r'C:\Program Files\Google\chromedriver-win64\chromedriver.exe'