import pandas as pd
import os
import re
import threading
from concurrent.futures import ThreadPoolExecutor
from PIL import Image
import io
import time
import requests
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å…¨å±€å˜é‡ ---
current = 0
lock = threading.Lock()
total = 0
# å®šä¹‰é‡å®šå‘ç›®æ ‡ï¼Œç”¨äº requests æ£€æŸ¥
REDIRECT_TARGET = 'https://wallpaperswide.com/' 

# --- å·¥å…·å‡½æ•° ---
def sanitize_filename(s):
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    return re.sub(r'[^\w\s\u4e00-\u9fff-.]', '', str(s)).strip().replace(' ', '-')

def is_direct_download(url):
    """åˆ¤æ–­æ˜¯å¦ä¸ºç›´æ¥å›¾ç‰‡é“¾æ¥ï¼ˆè¿™é‡Œä¿ç•™ï¼Œä½†ä»£ç ä¸­ä¸å†å¼ºåˆ¶æ£€æŸ¥ï¼‰"""
    img_exts = (".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp")
    return url.lower().endswith(img_exts)

# --- æ ¸å¿ƒä¸‹è½½å‡½æ•°ï¼šçº¯ç²¹çš„ requests ä¸‹è½½ (ç§»é™¤é‡è¯•) ---
def download_image_by_request(args):
    global current
    url, row, base_download_path, tag_folder_name, status_csv_path = args

    img_name = sanitize_filename(str(row.get('ImageName', 'image')))
    name, _ = os.path.splitext(img_name)

    # è‡ªåŠ¨è¯†åˆ«å›¾ç‰‡æ‰©å±•å
    ext = os.path.splitext(url.split("?")[0])[1].lower()
    # ç®€åŒ–æ‰©å±•åå¤„ç†
    if ext not in [".jpg", ".jpeg", ".png", ".webp", ".bmp"]:
         # å°è¯•æ ¹æ® headers ç¡®å®šï¼Œå¦åˆ™é»˜è®¤ .png
        try:
            head_response = requests.head(url, timeout=10, verify=False)
            content_type = head_response.headers.get('content-type', '').lower()
            if 'jpeg' in content_type or 'jpg' in content_type:
                ext = ".jpg"
            elif 'png' in content_type:
                ext = ".png"
            elif 'webp' in content_type:
                ext = ".webp"
            else:
                ext = ".png"
        except Exception:
            ext = ".png"


    file_name = f"{name}{ext}"
    safe_tag_folder = sanitize_filename(tag_folder_name)
    final_dir_path = os.path.join(base_download_path, safe_tag_folder)
    os.makedirs(final_dir_path, exist_ok=True)
    full_path = os.path.join(final_dir_path, file_name)

    def record_status(status, message=""):
        """åœ¨ä¸‹è½½çŠ¶æ€ CSV ä¸­è®°å½•ç»“æœ"""
        global current 
        with lock:
            current += 1
            print(f"[{current}/{total}] {status} {url}")
            df_status = pd.DataFrame([{
                "URL": url,
                "TAG": tag_folder_name,
                "ImageName": img_name,
                "Status": status,
                "Message": message,
                "SavedPath": full_path if status == "âœ…æˆåŠŸ" else ""
            }])
            df_status.to_csv(
                status_csv_path,
                mode='a',
                index=False,
                header=not os.path.exists(status_csv_path),
                encoding='utf-8-sig'
            )

    # ğŸš€ çº¯ç²¹çš„ requests ä¸‹è½½é€»è¾‘ (ç§»é™¤é‡è¯•å¾ªç¯)
    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/123.0.0.0 Safari/537.36"
        ),
        "Referer": "https://wallpaperswide.com/"
    }

    try:
        # ç›´æ¥ä½¿ç”¨ verify=False å’Œæ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼ˆå› ä¸ºæ²¡æœ‰é‡è¯•ï¼‰
        response = requests.get(
            url,
            headers=headers,
            timeout=120, # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥åº”å¯¹ç½‘ç»œæ…¢çš„æƒ…å†µ
            proxies={"http": None, "https": None},
            verify=False 
        )
        
        # æ£€æŸ¥é‡å®šå‘ 
        if response.url.startswith(REDIRECT_TARGET):
            record_status("âŒè·³è¿‡", f"ç›´é“¾é‡å®šå‘åˆ°ä¸»é¡µ: {response.url}")
            return False

        response.raise_for_status() # æ£€æŸ¥HTTPçŠ¶æ€ç 

    except Exception as e:
        # ä¸‹è½½å¤±è´¥ï¼Œç›´æ¥è®°å½•å¤±è´¥å¹¶è·³è¿‡
        record_status("âŒå¤±è´¥", f"ä¸‹è½½é”™è¯¯: {e.__class__.__name__} - {e}")
        return False

    # ä¿å­˜æ–‡ä»¶é€»è¾‘
    try:
        # å°è¯•ç”¨ PIL æ‰“å¼€å’Œä¿å­˜
        image = Image.open(io.BytesIO(response.content))
        # æ ¹æ®æ¨æ–­å‡ºçš„æ‰©å±•åé€‰æ‹©ä¿å­˜æ ¼å¼
        image_format = "PNG" if ext == ".png" else ("JPEG" if ext in ['.jpg', '.jpeg'] else "WEBP")
        image.save(full_path, image_format)
    except Exception as e:
        # å¦‚æœ PIL å¤±è´¥ï¼Œç›´æ¥å†™å…¥æ–‡ä»¶å†…å®¹
        try:
            with open(full_path, "wb") as f:
                f.write(response.content)
        except Exception as file_e:
             record_status("âŒå¤±è´¥", f"ä¿å­˜/å†™å…¥æ–‡ä»¶å¤±è´¥: {file_e}")
             return False

    record_status("âœ…æˆåŠŸ")
    return True


# --- ä¸»ç¨‹åºå…¥å£ (ä¿æŒä¸å˜) ---
if __name__ == "__main__":
    
    default_path = r"\\10.58.134.120\aigc2\01_æ•°æ®\çˆ¬è™«æ•°æ®\wallpaperswide\images"
    download_path = input(f"è¯·è¾“å…¥ä¸‹è½½è·¯å¾„ï¼ˆç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼š{default_path}):").strip() or default_path
    os.makedirs(download_path, exist_ok=True)

    csv_path = r"D:\work\çˆ¬è™«\çˆ¬è™«æ•°æ®\wallpaperswide\all_records3708 - å‰¯æœ¬.csv"
    status_csv_path = os.path.join(download_path, "download_status.csv")

    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"è¯»å– CSV æ–‡ä»¶å¤±è´¥ï¼š{e}")
        exit()

    # --- åŠ è½½å·²å®Œæˆçš„çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰ ---
    downloaded_urls = set()
    if os.path.exists(status_csv_path):
        try:
            df_status = pd.read_csv(status_csv_path)
            # æ£€æŸ¥ 'âœ…æˆåŠŸ' æˆ– 'âŒè·³è¿‡' çš„é“¾æ¥
            successful_urls = set(df_status.loc[df_status["Status"].isin(["âœ…æˆåŠŸ", "âŒè·³è¿‡", "âŒå¤±è´¥"]), "URL"].astype(str))
            downloaded_urls = successful_urls
            # ğŸ’¡ æ³¨æ„ï¼šè¿™é‡Œå°†"âŒå¤±è´¥"ä¹ŸåŠ å…¥å·²å¤„ç†é›†åˆï¼Œç¡®ä¿ä¸å†é‡è¯•å·²ç¡®è®¤å¤±è´¥çš„é“¾æ¥ã€‚
            print(f"âœ… æ£€æµ‹åˆ°å·²å¤„ç†è®°å½• {len(downloaded_urls)} æ¡ï¼ˆæˆåŠŸ/è·³è¿‡/å¤±è´¥ï¼‰ï¼Œå°†è·³è¿‡è¿™äº›ä»»åŠ¡ã€‚")
        except Exception:
            pass

    # --- æ„å»ºä»»åŠ¡åˆ—è¡¨ ---
    tasks = []
    total_records = len(df)
    for index, row in df.iterrows():
        url = str(row.get("URL"))
        tag = row.get("TAG")

        if pd.notna(url) and pd.notna(tag):
            if url in downloaded_urls:
                continue

            tag_folder_name = str(tag)
            tasks.append((url, row, download_path, tag_folder_name, status_csv_path))

    total = len(tasks)
    skipped_count = total_records - total
    print(f"æ€»è®°å½•æ•°ï¼š{total_records}")
    print(f"å·²è·³è¿‡ï¼ˆå·²å¤„ç†æˆ–æ— æ•ˆï¼‰ï¼š{skipped_count}")
    print(f"å¾…ä¸‹è½½ä»»åŠ¡æ•°ï¼š{total}")

    max_workers = 10
    print(f"ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹ä¸‹è½½...")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = executor.map(download_image_by_request, tasks) 

    success_count = sum(1 for r in results if r)
    print(f"\nä¸‹è½½å®Œæˆï¼æˆåŠŸï¼š{success_count}/{total}ï¼Œå¤±è´¥ï¼š{total - success_count}")
    print(f"ä¸‹è½½çŠ¶æ€å·²ä¿å­˜åˆ°ï¼š{status_csv_path}")