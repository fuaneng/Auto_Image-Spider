import requests
import os
import pandas as pd
import time
from concurrent.futures import ThreadPoolExecutor, as_completed # å¼•å…¥å¤šçº¿ç¨‹å…³é”®åº“

# === 1. é…ç½®ä¿¡æ¯å’Œè·¯å¾„è®¾ç½® ===
# **è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹å˜é‡**
csv_path = r"R:\py\Auto_Image-Spider\Selenium\v2ph\v2ph_data_251029_copy.csv"
download_root_dir = r"R:\py\Auto_Image-Spider\Selenium\v2ph\images"

# CSV æ–‡ä»¶ä¸­åŒ…å«å›¾ç‰‡ URL å’Œæ ‡é¢˜çš„åˆ—å
# CSV æ–‡ä»¶ä¸­åŒ…å«å›¾ç‰‡ URL å’Œæ ‡é¢˜çš„åˆ—å
# -----------------------------------------------
IMAGE_URL_COL = 'URL'      # <-- ğŸŒŸ ä¿®æ­£ï¼šä½¿ç”¨å®é™…çš„åˆ—å 'URL'
# -----------------------------------------------
TITLE_COL = 'Title'        # ä½¿ç”¨ 'Title' åˆ—ä½œä¸ºå­æ–‡ä»¶å¤¹å
# ä¸‹è½½è¯·æ±‚å¤´ (é€šå¸¸ç”¨äºç»•è¿‡é˜²ç›—é“¾æ£€æŸ¥)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    # !!! å…³é”® !!! æ¨¡æ‹Ÿä»åŸå§‹ç½‘ç«™å‘èµ·è¯·æ±‚
    'Referer': 'https://v2ph.com/' 
}

# å¤šçº¿ç¨‹é…ç½®
MAX_WORKERS = 10 # æœ€å¤§çº¿ç¨‹æ•°ï¼Œå³åŒæ—¶ä¸‹è½½ä»»åŠ¡çš„æ•°é‡

# ä¸‹è½½é—´éš”ï¼ˆç§’ï¼‰ï¼Œåœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å¯ä»¥é€‚å½“è°ƒå°æˆ–ç§»é™¤ï¼Œä½†ä¸ºäº†å®‰å…¨å’Œç¤¼è²Œï¼Œæˆ‘ä»¬ä¿ç•™å®ƒä½œä¸º**çº¿ç¨‹å¯åŠ¨å‰çš„å»¶è¿Ÿ**
# åœ¨çº¿ç¨‹æ± ä¸­ï¼Œçº¿ç¨‹ä¼šå¹¶å‘æ‰§è¡Œï¼Œè¿™ä¸ªå»¶è¿Ÿå¯ä»¥æ§åˆ¶ä»»åŠ¡æäº¤çš„é€Ÿåº¦ã€‚
DOWNLOAD_DELAY = 0.05 

# === 2. è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†æ–‡ä»¶åå’Œæ–‡ä»¶å¤¹å ===
def sanitize_name(name):
    """
    æ¸…ç†å­—ç¬¦ä¸²ï¼Œç§»é™¤åœ¨æ–‡ä»¶/æ–‡ä»¶å¤¹åä¸­ä¸å…è®¸çš„ç‰¹æ®Šå­—ç¬¦ã€‚
    """
    invalid_chars = '<>:"/\\|?*\n\r\t'
    for char in invalid_chars:
        name = name.replace(char, '_')
    return name.strip()

# === 3. æ ¸å¿ƒä¸‹è½½é€»è¾‘ (ä¿æŒä¸å˜ï¼Œä½†ç°åœ¨ç”±çº¿ç¨‹è°ƒç”¨) ===
def download_image(url, save_path, title_name):
    """
    ä¸‹è½½å•ä¸ªå›¾ç‰‡ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šçš„è·¯å¾„ã€‚
    è¿”å›ä¸€ä¸ªæè¿°ç»“æœçš„å­—ç¬¦ä¸²ã€‚
    """
    log_prefix = f"[Title: {title_name[:15]}]"

    if os.path.exists(save_path):
        return f"{log_prefix} [è·³è¿‡] æ–‡ä»¶å·²å­˜åœ¨: {os.path.basename(save_path)}"

    try:
        # å‘èµ· HTTP GET è¯·æ±‚
        response = requests.get(url, headers=HEADERS, stream=True, timeout=15)

        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code == 200:
            # å°†å›¾ç‰‡å†…å®¹å†™å…¥æ–‡ä»¶
            with open(save_path, 'wb') as f:
                # é€å—å†™å…¥ï¼Œé€‚ç”¨äºå¤§æ–‡ä»¶
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            file_size = os.path.getsize(save_path) / 1024  # è½¬æ¢ä¸º KB
            return f"{log_prefix} âœ… ä¸‹è½½æˆåŠŸï¼å¤§å°: {file_size:.2f} KB"

        elif response.status_code == 403:
            return f"{log_prefix} âŒ ä¸‹è½½å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code} (Forbidden)ã€‚æç¤º: å¯èƒ½æ˜¯é˜²ç›—é“¾ï¼Œè¯·æ£€æŸ¥ Refererã€‚"
        else:
            return f"{log_prefix} âŒ ä¸‹è½½å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}"
            
    except requests.exceptions.RequestException as e:
        return f"{log_prefix} âŒ è¯·æ±‚å‘ç”Ÿé”™è¯¯: {e}"
    except Exception as e:
        return f"{log_prefix} âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}"

# === 4. ä»»åŠ¡å‡†å¤‡å’Œæäº¤å‡½æ•° ===
def prepare_and_submit_task(executor, index, row, download_root_dir):
    """
    å‡†å¤‡ä¸‹è½½å‚æ•°ï¼Œåˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå¹¶å°†ä¸‹è½½ä»»åŠ¡æäº¤ç»™çº¿ç¨‹æ± ã€‚
    """
    image_url = row.get(IMAGE_URL_COL)
    title = str(row.get(TITLE_COL)) 
    
    # æ‰“å°æ­£åœ¨å‡†å¤‡å¤„ç†çš„è¡Œä¿¡æ¯
    # print(f"--- å‡†å¤‡æäº¤ç¬¬ {index + 1} è¡Œä»»åŠ¡ ---")

    if not image_url:
        print(f"  [è­¦å‘Š] ç¬¬ {index + 1} è¡Œå›¾ç‰‡ URL ä¸ºç©ºï¼Œè·³è¿‡ã€‚")
        return None

    # 1. æ¸…ç†æ ‡é¢˜å¹¶æ„å»ºå­æ–‡ä»¶å¤¹è·¯å¾„
    sanitized_title = sanitize_name(title)
    sub_dir = os.path.join(download_root_dir, sanitized_title)

    # 2. ç¡®ä¿å­æ–‡ä»¶å¤¹å­˜åœ¨ (éœ€è¦åœ¨ä¸»çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…å¤šä¸ªçº¿ç¨‹åŒæ—¶åˆ›å»ºæ–‡ä»¶å¤¹)
    if not os.path.exists(sub_dir):
        try:
            os.makedirs(sub_dir)
            print(f"  [åˆ›å»º] å­æ–‡ä»¶å¤¹: {sanitized_title}")
        except Exception as e:
            # å³ä½¿åœ¨ä¸»çº¿ç¨‹åˆ›å»ºï¼Œä¹Ÿå¯èƒ½å› ä¸ºç½‘ç»œè·¯å¾„æƒé™ç­‰é—®é¢˜å¤±è´¥
            print(f"  [é”™è¯¯] æ— æ³•åˆ›å»ºæ–‡ä»¶å¤¹ {sub_dir}: {e}")
            return None
    
    # 3. è·å–æ–‡ä»¶å
    try:
        file_name = os.path.basename(image_url).split('?')[0]
        if not file_name:
            file_name = f"image_{index + 1}.jpg"
    except:
        file_name = f"image_{index + 1}.jpg"

    # 4. å®Œæ•´çš„ä¿å­˜è·¯å¾„
    save_path = os.path.join(sub_dir, file_name)

    # 5. æäº¤ä¸‹è½½ä»»åŠ¡åˆ°çº¿ç¨‹æ± 
    future = executor.submit(download_image, image_url, save_path, title)
    return future


# === 5. ç¨‹åºä¸»å…¥å£ ===
def main():
    print(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤šçº¿ç¨‹ä¸‹è½½å›¾ç‰‡ (æœ€å¤§çº¿ç¨‹æ•°: {MAX_WORKERS})...")
    print(f"CSV è·¯å¾„: {csv_path}")
    print(f"ä¸‹è½½æ ¹ç›®å½•: {download_root_dir}\n")

    # ç¡®ä¿ä¸‹è½½æ ¹ç›®å½•å­˜åœ¨
    if not os.path.exists(download_root_dir):
        os.makedirs(download_root_dir)
        print(f"åˆ›å»ºä¸‹è½½æ ¹ç›®å½•: {download_root_dir}")

    try:
        # è¯»å– CSV æ–‡ä»¶
        df = pd.read_csv(csv_path)
        total_rows = len(df)
        print(f"æˆåŠŸè¯»å– {total_rows} è¡Œæ•°æ®ã€‚")
        
        # æ£€æŸ¥å…³é”®åˆ—æ˜¯å¦å­˜åœ¨
        if IMAGE_URL_COL not in df.columns or TITLE_COL not in df.columns:
            print(f"\nğŸš¨ é”™è¯¯: CSV æ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—ã€‚")
            print(f"  å¿…éœ€çš„åˆ—æœ‰: '{IMAGE_URL_COL}' å’Œ '{TITLE_COL}'")
            print(f"  å®é™…æ‹¥æœ‰çš„åˆ—: {list(df.columns)}")
            return

        # ä½¿ç”¨ ThreadPoolExecutor (ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç¡®ä¿çº¿ç¨‹æ± åœ¨ç»“æŸæ—¶è‡ªåŠ¨å…³é—­)
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = []
            
            # 1. æäº¤æ‰€æœ‰ä»»åŠ¡
            for index, row in df.iterrows():
                future = prepare_and_submit_task(executor, index, row, download_root_dir)
                if future:
                    futures.append(future)
                
                # åœ¨æäº¤ä»»åŠ¡ä¹‹é—´è®¾ç½®ä¸€ä¸ªå¾®å°çš„å»¶è¿Ÿï¼Œä»¥æ§åˆ¶ä»»åŠ¡æäº¤é€Ÿç‡
                time.sleep(DOWNLOAD_DELAY)
            
            print(f"\nâœ… å·²æäº¤ {len(futures)} ä¸ªä¸‹è½½ä»»åŠ¡åˆ°çº¿ç¨‹æ± ï¼Œå¼€å§‹ç­‰å¾…ä¸‹è½½å®Œæˆ...")
            start_time = time.time()

            # 2. ç­‰å¾…å¹¶å¤„ç†ç»“æœ
            # as_completed ä¼šåœ¨ä»»åŠ¡å®Œæˆåç«‹å³è¿”å› Future å¯¹è±¡ï¼Œå¯ä»¥å®æ—¶æ‰“å°ç»“æœ
            for i, future in enumerate(as_completed(futures)):
                try:
                    result = future.result() # è·å–çº¿ç¨‹çš„è¿”å›ç»“æœ (å³ download_image çš„è¿”å›å€¼)
                    print(f"[{i + 1}/{len(futures)}] {result}")
                except Exception as e:
                    print(f"  [çº¿ç¨‹é”™è¯¯] ä»»åŠ¡æ‰§è¡Œå‘ç”Ÿå¼‚å¸¸: {e}")

        end_time = time.time()
        print(f"\nğŸ‰ æ‰€æœ‰å›¾ç‰‡ä¸‹è½½ä»»åŠ¡å®Œæˆï¼æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    except FileNotFoundError:
        print(f"\nğŸš¨ é”™è¯¯: æ‰¾ä¸åˆ°æŒ‡å®šçš„ CSV æ–‡ä»¶: {csv_path}")
    except pd.errors.EmptyDataError:
        print("\nğŸš¨ é”™è¯¯: CSV æ–‡ä»¶ä¸ºç©ºã€‚")
    except Exception as e:
        print(f"\nğŸš¨ å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")

if __name__ == "__main__":
    main()