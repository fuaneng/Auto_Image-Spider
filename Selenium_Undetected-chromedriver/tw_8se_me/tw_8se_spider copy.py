import os
import re
import csv
import time
import random
import traceback
import threading
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ---------------- é…ç½® ----------------
CUSTOM_BROWSER_PATH = r"C:\Program Files\Google\Chrome\Application\chrome.exe"
CHROMEDRIVER_PATH = r"C:\Program Files\Google\chromedriver-win64\chromedriver.exe"

BASE_URL = "https://xchina.fit"
MODEL_ID_FILE = r"R:\py\Auto_Image-Spider\Selenium_Undetected-chromedriver\tw_8se_me\model_id.txt"
CSV_OUTPUT_PATH = r"R:\py\Auto_Image-Spider\Selenium_Undetected-chromedriver\tw_8se_me\results.csv"
# âœ… æ–°å¢ï¼šCSV è¾“å‡ºç›®å½•ï¼ˆæ¯ä¸ªæ¨¡ç‰¹ä¸€ä¸ª CSVï¼‰
CSV_OUTPUT_DIR = r"R:\py\Auto_Image-Spider\Selenium_Undetected-chromedriver\tw_8se_me\csvs"
DOWNLOAD_ROOT = r"R:\py\Auto_Image-Spider\Selenium_Undetected-chromedriver\tw_8se_me\models"

PAGE_LOAD_TIMEOUT = 30
MAX_WORKERS = 10
DOWNLOAD_ENABLED = False  # â† æ§åˆ¶æ˜¯å¦ä¸‹è½½å›¾ç‰‡, å»ºè®®ä¿æŒ True, å¦åˆ™ä»…é‡‡é›†ä¿¡æ¯ False ï¼ï¼ï¼æ³¨æ„è¯¥è„šæœ¬ç›®å‰æ— æ³•æ­£å¸¸ä¸‹è½½å›¾ç‰‡ï¼Œä»…é‡‡é›†ä¿¡æ¯ï¼Œåç»­ä¼šä¿®å¤è¯¥é—®é¢˜ã€‚å¦‚æœä¸‹è½½å›¾ç‰‡ï¼Œè¯·å°†ä½¿ç”¨ç‹¬ç«‹çš„ä¸‹è½½è„šæœ¬ã€‚
# -------------------------------------


class XChinaSpider:
    def __init__(self):
        self.csv_lock = threading.Lock()
        self.download_tasks = []
        self.executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)
        self.driver = None
        self._init_driver()

    def _init_driver(self):
        """åˆå§‹åŒ– Selenium é©±åŠ¨"""
        from selenium.webdriver.chrome.options import Options
        options = Options()
        options.binary_location = CUSTOM_BROWSER_PATH
        options.add_argument("--no-sandbox")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-blink-features=AutomationControlled")
        service = Service(CHROMEDRIVER_PATH)
        self.driver = webdriver.Chrome(service=service, options=options)
        self.driver.implicitly_wait(5)
        print("[âœ”] å¯åŠ¨ Chrome æˆåŠŸ")

    # ----------------- å·¥å…·å‡½æ•° -----------------
    def parse_model_file(self):
        """è§£æ model_id.txt æ–‡ä»¶"""
        pairs, lines = [], []
        with open(MODEL_ID_FILE, 'r', encoding='utf-8') as f:
            for raw in f:
                line = raw.strip()
                if not line or line.startswith('#'):
                    continue
                if '#' in line:
                    line = line.split('#', 1)[0].strip()
                if line:
                    lines.append(line)
        for i in range(0, len(lines) - 1, 2):
            pairs.append((lines[i].strip(), lines[i + 1].strip()))
        print(f"[i] å…±è§£æåˆ° {len(pairs)} ä½æ¨¡ç‰¹")
        return pairs

    def write_to_csv(self, title, image_name, url, model_name):
        """å†™å…¥ CSVï¼ˆæ¯ä¸ª model å•ç‹¬è¡¨æ ¼ï¼‰"""
        try:
            with self.csv_lock:
                os.makedirs(CSV_OUTPUT_DIR, exist_ok=True)
                csv_path = os.path.join(CSV_OUTPUT_DIR, f"{self._sanitize_filename(model_name)}.csv")

                is_empty = not os.path.exists(csv_path) or os.stat(csv_path).st_size == 0

                with open(csv_path, 'a', newline='', encoding='utf-8-sig') as f:
                    writer = csv.writer(f)
                    if is_empty:
                        writer.writerow(['Title', 'ImageName', 'URL', 'ModelName'])
                    writer.writerow([title, image_name, url, model_name])
        except Exception as e:
            print(f"[âœ—] å†™å…¥ {model_name}.csv å‡ºé”™: {e}")

    @staticmethod
    def _sanitize_filename(name):
        return re.sub(r'[\\/*?:"<>|]', '_', name)

    # ----------------- ä¸‹è½½éƒ¨åˆ† -----------------
    def _download_image(self, url: str, save_path: str, retries=3, timeout=15):
        """ä¸‹è½½å•å¼ å›¾ç‰‡"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        if os.path.exists(save_path):
            return
        for _ in range(retries):
            try:
                r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=timeout)
                if r.status_code == 200 and r.content:
                    with open(save_path, 'wb') as f:
                        f.write(r.content)
                    return
            except Exception:
                time.sleep(1.5 + random.random())
        print(f"[âœ—] ä¸‹è½½å¤±è´¥: {url}")

    def schedule_download(self, model_name, title, image_urls):
        """æ·»åŠ ä¸‹è½½ä»»åŠ¡"""
        base_dir = os.path.join(DOWNLOAD_ROOT, model_name, self._sanitize_filename(title))
        for url in image_urls:
            img_name = os.path.basename(url)
            save_path = os.path.join(base_dir, img_name)
            self.download_tasks.append(self.executor.submit(self._download_image, url, save_path))

    def wait_for_downloads(self):
        """ç­‰å¾…ä¸‹è½½å®Œæˆ"""
        if not self.download_tasks:
            return
        print(f"[â³] ç­‰å¾… {len(self.download_tasks)} ä¸ªä¸‹è½½ä»»åŠ¡å®Œæˆ...")
        for future in as_completed(self.download_tasks):
            future.result()
        print("[âœ”] æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆ")

    # ----------------- æ ¸å¿ƒé€»è¾‘ -----------------
    def _try_load_model_page(self, model_id: str):
        """ä¼˜å…ˆåŠ è½½å®Œæ•´ä½œå“é¡µï¼ˆå¸¦åˆ†é¡µï¼‰"""
        url_full = f"{BASE_URL}/photos/model-{model_id}.html"
        url_basic = f"{BASE_URL}/model/id-{model_id}.html"

        for url in [url_full, url_basic]:
            print(f"[â†’] å°è¯•åŠ è½½: {url}")
            self.driver.get(url)
            try:
                WebDriverWait(self.driver, PAGE_LOAD_TIMEOUT).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'div.item.photo'))
                )
                print(f"[âœ”] æˆåŠŸåŠ è½½: {url}")
                return url
            except Exception:
                print(f"[!] é¡µé¢æœªåŠ è½½æˆåŠŸ: {url}")
                continue
        return None

    def _parse_gallery_elements(self, model_name: str):
        """è§£æå½“å‰é¡µä½œå“åˆ—è¡¨"""
        works = self.driver.find_elements(By.CSS_SELECTOR, 'div.item.photo')
        if not works:
            return False

        for w in works:
            try:
                a_tag = w.find_element(By.CSS_SELECTOR, 'a[href^="/photo/id-"]')
                title = a_tag.get_attribute('title') or a_tag.text or 'Untitled'

                img_div = w.find_element(By.CSS_SELECTOR, 'div.img')
                style = img_div.get_attribute('style')
                m = re.search(r"url\(['\"]?(https://[^'\"]+)['\"]?\)", style)
                if not m:
                    continue
                thumb_url = m.group(1)
                base_url = thumb_url.rsplit('/', 1)[0] + "/"

                count_div = w.find_element(By.CSS_SELECTOR, 'div.tags > div')
                m2 = re.search(r"(\d+)", count_div.text)
                total = int(m2.group(1)) if m2 else 0
                if total == 0:
                    continue

                image_urls = [f"{base_url}{i:04d}.jpg" for i in range(1, total + 1)]

                # å†™å…¥ CSV
                for url in image_urls:
                    self.write_to_csv(title, os.path.basename(url), url, model_name)

                print(f"[+] {model_name} | {title} | {total} å¼  âœ…")

                if DOWNLOAD_ENABLED:
                    self.schedule_download(model_name, title, image_urls)
            except Exception as e:
                print(f"[âœ—] è§£æä½œå“å¤±è´¥: {e}")
                traceback.print_exc()
        return True

    def fetch_model_page_galleries_fast(self, model_id: str, model_name: str):
        """çˆ¬å–æ‰€æœ‰åˆ†é¡µä½œå“"""
        base_url = self._try_load_model_page(model_id)
        if not base_url:
            print(f"[âœ—] æ— æ³•åŠ è½½æ¨¡ç‰¹ä½œå“é¡µ: {model_id}")
            return

        # ç¬¬ä¸€é¡µ
        page = 1
        while True:
            url = base_url if page == 1 else base_url.replace('.html', f'/{page}.html')
            print(f"[â†’] åŠ è½½åˆ†é¡µ: {url}")
            self.driver.get(url)
            try:
                WebDriverWait(self.driver, PAGE_LOAD_TIMEOUT).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.item.photo'))
                )
            except Exception:
                pass

            has_works = self._parse_gallery_elements(model_name)
            if not has_works:
                print(f"[âœ”] {model_name} æ‰€æœ‰ä½œå“å·²åŠ è½½å®Œ (å…± {page-1} é¡µ)")
                break

            page += 1
            time.sleep(1.5 + random.random())

    # ----------------- ä¸»æµç¨‹ -----------------
    def run(self):
        models = self.parse_model_file()
        for model_id, model_name in models:
            try:
                self.fetch_model_page_galleries_fast(model_id, model_name)
            except Exception as e:
                print(f"[âœ—] æ¨¡ç‰¹ {model_name} å‡ºé”™: {e}")
        self.driver.quit()
        if DOWNLOAD_ENABLED:
            self.wait_for_downloads()
        print("[âœ”] å…¨éƒ¨ä»»åŠ¡å®Œæˆ")


# ----------------- å¯åŠ¨ -----------------
if __name__ == "__main__":
    print("ğŸ”¨ğŸ¤– xchina.fit è‡ªåŠ¨ç¿»é¡µç‰ˆçˆ¬è™«å¯åŠ¨ä¸­...")
    spider = XChinaSpider()
    spider.run()
    print("ä»»åŠ¡å®Œæˆ âœ…")
